{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dabdaa-6203-4397-83cf-107242b91ef8",
   "metadata": {},
   "source": [
    "# Problem: \n",
    "Given a set of N coordinates as (X,Y) pairs, we want to compute how many\n",
    "coordinates are within R meters of an (X,Y) centroid where the distance metric is Euclidean.\n",
    "Goal: Design and write a class that is able to solve instances of this problem. The interface\n",
    "should be simple, documented, and allow a typical developer to use your API to efficiently query\n",
    "coordinates and centroids to find coordinate counts in proximity to centroids.\n",
    "Using this class and the sample data provided to provide solutions to the following questions.\n",
    "1. How many coordinates are within 5 meters of at least one of the centroids?\n",
    "2. How many coordinates are within 10 meters of at least one of the centroids?\n",
    "3. What is the minimum radius R such that 80 percent of the coordinates are within R meters of at least one of K centroids?\n",
    "4. Bonus: What is the maximum radius R such that the number of coordinates within a distance strictly less than R of any centroid is at most 1000?\n",
    "\n",
    "Files:\n",
    "- coordinates.csv: contains 1 million X,Y pairs with a header, units in meters\n",
    "- centroids.csv: contains 1000 cluster centroids as X,Y pairs with a header, units in meters\n",
    "\n",
    "Deliverable:\n",
    "- State your assumptions. Provide direction to run your code and to recreate the solutionsto the questions. This includes installing all the dependencies, specifying path, or running the executable. Assume the developer executing and validating your code using Linux distribution.\n",
    "- Please provide simple unit tests for your software.\n",
    "- Provide solutions along with runtimes and peak memory usage for each question.\n",
    "- Document the computation and memory complexity of each API call in your class as a function of the K centroids and N coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfbfdc9-3c62-440e-b73b-bbf27ee5d2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-05 09:49:39--  https://builds.openlogic.com/downloadJDK/openlogic-openjdk/8u332-b09/openlogic-openjdk-8u332-b09-linux-x64.tar.gz\n",
      "Resolving builds.openlogic.com (builds.openlogic.com)... 54.192.150.64, 54.192.150.116, 54.192.150.37, ...\n",
      "Connecting to builds.openlogic.com (builds.openlogic.com)|54.192.150.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 105558622 (101M) [application/x-gzip]\n",
      "Saving to: ‘/tmp/java/openlogic-openjdk-8u332-b09-linux-x64.tar.gz’\n",
      "\n",
      "openlogic-openjdk-8 100%[===================>] 100.67M  59.8MB/s    in 1.7s    \n",
      "\n",
      "2024-01-05 09:49:41 (59.8 MB/s) - ‘/tmp/java/openlogic-openjdk-8u332-b09-linux-x64.tar.gz’ saved [105558622/105558622]\n",
      "\n",
      "/tmp/java/openlogic-openjdk-8u332-b09-linux-x64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\"\"\"\n",
    "Since the testing suite doesn't support testing on Dataproc clusters,\n",
    "the testing environment is setup to replicate Dataproc via the following steps:\n",
    "\"\"\"\n",
    "JAVA_VER = \"8u332-b09\"\n",
    "JAVA_FOLDER = \"/tmp/java\"\n",
    "FILE_NAME = f\"openlogic-openjdk-{JAVA_VER}-linux-x64\"\n",
    "TAR_FILE = f\"{JAVA_FOLDER}/{FILE_NAME}.tar.gz\"\n",
    "DOWNLOAD_LINK = f\"https://builds.openlogic.com/downloadJDK/openlogic-openjdk/{JAVA_VER}/openlogic-openjdk-{JAVA_VER}-linux-x64.tar.gz\"\n",
    "! rm -rf $JAVA_FOLDER\n",
    "! mkdir $JAVA_FOLDER\n",
    "# Download Open JDK 8. Spark requires Java to execute.\n",
    "! wget -P $JAVA_FOLDER $DOWNLOAD_LINK\n",
    "os.environ[\"JAVA_HOME\"] = f\"{JAVA_FOLDER}/{FILE_NAME}\"\n",
    "! tar -zxf $TAR_FILE -C $JAVA_FOLDER\n",
    "! echo $JAVA_HOME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9a158f-c908-4fcf-86a5-6cec89493c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"PairwiseDistanceExample\").getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29415244-8fe0-4d91-97c0-2036c792c436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beed5295-1752-4299-a147-20017ad24500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+\n",
      "|                  X|                  Y|\n",
      "+-------------------+-------------------+\n",
      "| -115.1140124595813| -498.9879464124197|\n",
      "|-0.5227499155640025| -186.5801101930945|\n",
      "|  -39.4848803518455| -459.0236264356627|\n",
      "| -4.918948978550608| 145.66092744140258|\n",
      "|  -60.7369212403257|  264.4701308991166|\n",
      "|-331.46583985621436| 320.76423216748515|\n",
      "|-135.58374696646203| 26.575119653588942|\n",
      "|-158.66413434688965| -209.2160760552777|\n",
      "| 296.83864590885764| 391.02348464829294|\n",
      "|-119.31911868661338| 239.12040824321247|\n",
      "|-30.051884126232498| -56.15738478405685|\n",
      "| 350.49023203314675|-461.99648415979146|\n",
      "|-17.254590642131085| -9.502172560105105|\n",
      "|  34.60422416929665|  191.3128473521155|\n",
      "|-194.41418640528352| -249.8722183939046|\n",
      "|   356.608984177928| 187.69701273208983|\n",
      "|  321.3381541837739|  9.179356344668044|\n",
      "|-127.88076183785635| -271.3613821858672|\n",
      "| 204.34446941315863|  -476.189158735473|\n",
      "|  396.4524423252325|-409.84229992212863|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read CSV files\n",
    "centroids_df = spark.read.csv(\"Data/centroids.csv.bz2\", header=True, inferSchema=True)\n",
    "\n",
    "centroids_df.printSchema()\n",
    "# Show the DataFrame\n",
    "centroids_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9288bf6d-474f-4af4-b31e-7f560b742111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+\n",
      "|                  X|                  Y|\n",
      "+-------------------+-------------------+\n",
      "| 133.37999002739875|   70.2259406546376|\n",
      "| 235.79901946653808|-299.95706910083453|\n",
      "| 192.55720004008475|  18.26500093427191|\n",
      "|-17.823904060029953|-1.9179740034930717|\n",
      "|-441.00303111998005|-425.34627850821437|\n",
      "| -416.4018644934994|  86.63118699773204|\n",
      "|  280.6479457858666| -424.0130678291138|\n",
      "|  -279.730515078068|-205.86880095176195|\n",
      "| 128.35820257781907| -93.83617444138126|\n",
      "| 163.62371178554403|  62.64532543769148|\n",
      "| -46.49656000485959|  339.6043779426013|\n",
      "|  343.1579293057832|-287.92617948544654|\n",
      "|-115.70715144878952|  98.46029667186691|\n",
      "|  506.5424974792967| 199.19433496509072|\n",
      "|  47.29679680565559| 408.15772702869225|\n",
      "|  444.9502623068463|   272.445880020846|\n",
      "|-185.18905424350012|-240.33513312645408|\n",
      "|-362.65661099184814|-381.71219076824815|\n",
      "| 436.59890193014843| -400.7481795883354|\n",
      "|  394.5224194261471|-16.624095093978994|\n",
      "+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read CSV files\n",
    "coordinates_df = spark.read.csv(\"Data/coordinates.csv.bz2\", header=True, inferSchema=True)\n",
    "\n",
    "coordinates_df.printSchema()\n",
    "# Show the DataFrame\n",
    "coordinates_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49f934ec-a286-49ab-aebd-151a17578825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a PySpark UDF for pairwise distance calculation\n",
    "def pairwise_distance_udf(coord_x, coord_y, centroid_x, centroid_y):\n",
    "    return F.sqrt((F.pow(coord_x - centroid_x, 2) + F.pow(coord_y - centroid_y, 2)))\n",
    "pairwise_distance = F.udf(pairwise_distance_udf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df2bef6d-b6b4-4a5d-ad70-040a2063ddb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with pairwise distances\n",
    "distances_df = coordinates_df.crossJoin(centroids_df).withColumn(\n",
    "    \"distance\",\n",
    "    pairwise_distance(\n",
    "        coordinates_df[\"X\"],\n",
    "        coordinates_df[\"Y\"],\n",
    "        centroids_df[\"X\"],\n",
    "        centroids_df[\"Y\"],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eccacbd0-acda-4422-a9d6-5757c4d1e6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `coordinates_X` cannot be resolved. Did you mean one of the following? [`distance`, `X`, `X`, `Y`, `Y`].;\n'Aggregate ['coordinates_X, 'coordinates_Y], ['coordinates_X, 'coordinates_Y, 'count(distinct 'centroids_X, 'centroids_Y) AS count_within_5#352]\n+- Filter (cast(distance#341 as double) <= 5.0)\n   +- Project [X#281, Y#282, X#248, Y#249, pairwise_distance_udf(X#281, Y#282, X#248, Y#249)#340 AS distance#341]\n      +- Join Cross\n         :- Relation [X#281,Y#282] csv\n         +- Relation [X#248,Y#249] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m radius_10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Count coordinates within 5 meters of at least one centroid\u001b[39;00m\n\u001b[1;32m      6\u001b[0m count_within_5 \u001b[38;5;241m=\u001b[39m \u001b[43mdistances_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mradius_5\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoordinates_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoordinates_Y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m----> 8\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountDistinct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcentroids_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcentroids_Y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount_within_5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-sys-practice-yHkat0Rk-py3.10/lib/python3.10/site-packages/pyspark/sql/group.py:186\u001b[0m, in \u001b[0;36mGroupedData.agg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m exprs), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall exprs should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     exprs \u001b[38;5;241m=\u001b[39m cast(Tuple[Column, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], exprs)\n\u001b[0;32m--> 186\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-sys-practice-yHkat0Rk-py3.10/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-sys-practice-yHkat0Rk-py3.10/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `coordinates_X` cannot be resolved. Did you mean one of the following? [`distance`, `X`, `X`, `Y`, `Y`].;\n'Aggregate ['coordinates_X, 'coordinates_Y], ['coordinates_X, 'coordinates_Y, 'count(distinct 'centroids_X, 'centroids_Y) AS count_within_5#352]\n+- Filter (cast(distance#341 as double) <= 5.0)\n   +- Project [X#281, Y#282, X#248, Y#249, pairwise_distance_udf(X#281, Y#282, X#248, Y#249)#340 AS distance#341]\n      +- Join Cross\n         :- Relation [X#281,Y#282] csv\n         +- Relation [X#248,Y#249] csv\n"
     ]
    }
   ],
   "source": [
    "# Define the radius values\n",
    "radius_5 = 5.0\n",
    "radius_10 = 10.0\n",
    "\n",
    "# Count coordinates within 5 meters of at least one centroid\n",
    "count_within_5 = distances_df.filter(distances_df[\"distance\"] <= radius_5).groupBy(\n",
    "    \"coordinates_X\", \"coordinates_Y\"\n",
    ").agg(F.countDistinct(\"centroids_X\", \"centroids_Y\").alias(\"count_within_5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d7d9807-2415-4311-a6e3-210fa7f3133c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `coordinates_X` cannot be resolved. Did you mean one of the following? [`distance`, `X`, `X`, `Y`, `Y`].;\n'Aggregate ['coordinates_X, 'coordinates_Y], ['coordinates_X, 'coordinates_Y, percentile_approx(cast(distance#341 as double), cast(80.0 as double), 10000, 0, 0) AS min_radius#358]\n+- Project [X#281, Y#282, X#248, Y#249, pairwise_distance_udf(X#281, Y#282, X#248, Y#249)#340 AS distance#341]\n   +- Join Cross\n      :- Relation [X#281,Y#282] csv\n      +- Relation [X#248,Y#249] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate minimum radius R for 80% of coordinates\u001b[39;00m\n\u001b[1;32m      2\u001b[0m quantile_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[0;32m----> 3\u001b[0m min_radius_df \u001b[38;5;241m=\u001b[39m \u001b[43mdistances_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoordinates_X\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoordinates_Y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpercentile_approx(distance, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquantile_value\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin_radius\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-sys-practice-yHkat0Rk-py3.10/lib/python3.10/site-packages/pyspark/sql/group.py:186\u001b[0m, in \u001b[0;36mGroupedData.agg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m exprs), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall exprs should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     exprs \u001b[38;5;241m=\u001b[39m cast(Tuple[Column, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], exprs)\n\u001b[0;32m--> 186\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-sys-practice-yHkat0Rk-py3.10/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-sys-practice-yHkat0Rk-py3.10/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `coordinates_X` cannot be resolved. Did you mean one of the following? [`distance`, `X`, `X`, `Y`, `Y`].;\n'Aggregate ['coordinates_X, 'coordinates_Y], ['coordinates_X, 'coordinates_Y, percentile_approx(cast(distance#341 as double), cast(80.0 as double), 10000, 0, 0) AS min_radius#358]\n+- Project [X#281, Y#282, X#248, Y#249, pairwise_distance_udf(X#281, Y#282, X#248, Y#249)#340 AS distance#341]\n   +- Join Cross\n      :- Relation [X#281,Y#282] csv\n      +- Relation [X#248,Y#249] csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate minimum radius R for 80% of coordinates\n",
    "quantile_value = 0.8\n",
    "min_radius_df = distances_df.groupBy(\"coordinates_X\", \"coordinates_Y\").agg(\n",
    "    F.expr(f\"percentile_approx(distance, {quantile_value * 100})\").alias(\"min_radius\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb7636e-cd27-46d5-8297-c3ad7f76ed00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mstop()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ml_sys",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "ml_sys",
   "language": "python",
   "name": "ml_sys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
