{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "\n",
    "In the following code, we are setting up the environment by importing required libraries.\n",
    "- `openml` for accessing datasets from the OpenML repository.\n",
    "- `time` for handling time-related operations.\n",
    "- `jax` for high-performance numerical computing.\n",
    "- `matplotlib.pyplot` for plotting graphs.\n",
    "- Various JAX modules for specific functionalities like gradient computation, random number generation, etc.\n",
    "- `typing` for type hinting.\n",
    "- `IPython.display.Markdown` for displaying Markdown content in IPython.\n",
    "- `tqdm.auto.trange` for creating a tqdm progress bar.\n",
    "\n",
    "The variable `SEED` is set to 404 for seeding random number generators, ensuring reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Union, Tuple, Iterable, List\n",
    "from IPython.display import Markdown\n",
    "from tqdm.auto import trange\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "SEED = 404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the MNIST Dataset for Machine Learning\n",
    "\n",
    "In this code snippet, we delve into the MNIST dataset using the OpenML library. The MNIST dataset is a collection of handwritten digits widely used in machine learning and computer vision. Let's break down the steps:\n",
    "\n",
    "1. [**Fetching the Dataset:**](#fetching-the-dataset)\n",
    "   We use OpenML to retrieve the MNIST dataset, a crucial resource for developing and testing machine learning models. The dataset comprises images of handwritten digits, each labeled with its corresponding numeric value.\n",
    "\n",
    "2. [**Extracting Features and Labels:**](#extracting-features-and-labels)\n",
    "   With the fetched dataset, we extract the features (X) and labels (y). The features represent the pixel values of the handwritten digits, while the labels indicate the numeric values they represent. This step is fundamental for training machine learning models.\n",
    "\n",
    "3. [**Data Preparation:**](#data-preparation)\n",
    "   To ensure data compatibility, we convert the label data to integers. This step is essential for downstream tasks like model training, where proper data types are crucial.\n",
    "\n",
    "The provided code offers a concise way to access and understand the MNIST dataset, laying the groundwork for future machine learning endeavors. Stay tuned for further exploration and analysis!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n",
       "**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n",
       "**Please cite**:  \n",
       "\n",
       "The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n",
       "\n",
       "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n",
       "\n",
       "With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n",
       "\n",
       "The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset ' MNIST '\n",
    "dataset = openml.datasets.get_dataset(dataset_id=554, \n",
    "                                      download_data=False, \n",
    "                                      download_qualities=False, \n",
    "                                      download_features_meta_data=False)\n",
    "Markdown(dataset.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and target variable (y) from the MNIST dataset\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, \n",
    "                                    dataset_format=\"dataframe\")\n",
    "\n",
    "# Ensure the target variable is of integer type\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape:(70000, 784)\n",
      "Label shape:(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature shape:{X.shape}')\n",
    "print(f'Label shape:{y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "X_test shape: (10000, 784)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Set the number of examples for training and testing follow dataset.description\n",
    "train_size = 60000\n",
    "test_size = 10000\n",
    "\n",
    "# Split the data manually\n",
    "X_train, X_test = X.iloc[:train_size, :].to_numpy(), X.iloc[train_size:train_size + test_size, :].to_numpy()\n",
    "y_train, y_test = y.iloc[:train_size].to_numpy(), y.iloc[train_size:train_size + test_size].to_numpy()\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training a Neural Network with JAX\n",
    "\n",
    "In this step, we implement a simple neural network using the JAX library, a powerful tool for high-performance numerical computing. Let's break down the code:\n",
    "\n",
    "### 1. Initializing Network Parameters\n",
    "   - `random_layer_params(m, n, key, scale=1e-2)`: Helper function to randomly initialize weights and biases for a dense neural network layer.\n",
    "   - `init_network_params(sizes, key)`: Initializes all layers for a fully-connected neural network with specified sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1e-2) -> Tuple:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - m (int): Number of input neurons.\n",
    "    - n (int): Number of output neurons.\n",
    "    - key (jax.random.PRNGKey): Random key for reproducibility.\n",
    "    - scale (float): Scaling factor for weight and bias initialization.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple: Tuple containing weight and bias arrays.\n",
    "    \"\"\"\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - sizes (List[int]): List of layer sizes.\n",
    "    - key (jax.random.PRNGKey): Random key for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple]: List of tuples containing weight and bias arrays for each layer.\n",
    "    \"\"\"\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Activation Function\n",
    "   - `relu(x)`: Rectified Linear Unit (ReLU) activation function applied element-wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - x (array): Input array.\n",
    "\n",
    "    Returns:\n",
    "    - array: Output array after applying ReLU activation function.\n",
    "    \"\"\"\n",
    "    return jnp.maximum(0, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prediction and Batch Processing\n",
    "   - `predict(params, image)`: Makes per-example predictions using the initialized parameters.\n",
    "   - `batched_predict(params, images)`: A batched version of the `predict` function using JAX's `vmap` for efficient processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp # Compute the log of the sum of exponentials of input elements\n",
    "def predict(params, image):\n",
    "    \"\"\"\n",
    "    Predicts output given input using a fully-connected neural network.\n",
    "\n",
    "    Args:\n",
    "    - params (List[Tuple]): List of tuples containing weight and bias arrays for each layer.\n",
    "    - image (array): Input data.\n",
    "\n",
    "    Returns:\n",
    "    - array: Predicted logits.\n",
    "    \"\"\"\n",
    "    # per-example predictions\n",
    "    activations = image\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "  \n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)\n",
    "\n",
    "# Make a batched version of the `predict` function\n",
    "batched_predict = vmap(predict, in_axes=(None, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. One-Hot Encoding\n",
    "   - `one_hot(x, k)`: Creates a one-hot encoding of input labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k):\n",
    "    \"\"\"\n",
    "    Create a one-hot encoding of x of size k.\n",
    "\n",
    "    Args:\n",
    "    - x (array): Input array of integer labels.\n",
    "    - k (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "    - array: One-hot encoded array.\n",
    "    \"\"\"\n",
    "    return jax.nn.one_hot(x, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation Metrics\n",
    "   - `accuracy(params, images, targets)`: Computes accuracy of predictions.\n",
    "   - `loss_fn(params, images, targets)`: Computes the cross-entropy loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, images, targets):\n",
    "    \"\"\"\n",
    "    Compute accuracy of predictions.\n",
    "\n",
    "    Args:\n",
    "    - params (List[Tuple]): List of tuples containing weight and bias arrays for each layer.\n",
    "    - images (array): Input data.\n",
    "    - targets (array): Target labels.\n",
    "\n",
    "    Returns:\n",
    "    - float: Accuracy.\n",
    "    \"\"\"\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "def loss_fn(params, images, targets):\n",
    "    \"\"\"\n",
    "    Compute the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "    - params (List[Tuple]): List of tuples containing weight and bias arrays for each layer.\n",
    "    - images (array): Input data.\n",
    "    - targets (array): Target labels.\n",
    "\n",
    "    Returns:\n",
    "    - float: Cross-entropy loss.\n",
    "    \"\"\"\n",
    "    preds = batched_predict(params, images)\n",
    "    return -jnp.mean(preds * targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Parameter Update\n",
    "   - `update(params, x, y, lr=1e-4)`: Updates model parameters using gradient descent. The `@jit` decorator optimizes the function for performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Update the model parameters using gradient descent.\n",
    "\n",
    "    Args:\n",
    "    - params (List[Tuple]): List of tuples containing weight and bias arrays for each layer.\n",
    "    - x (array): Input data.\n",
    "    - y (array): Target labels.\n",
    "    - lr (float): Learning rate for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "    - List[Tuple]: Updated model parameters.\n",
    "    \"\"\"\n",
    "    grads = grad(loss_fn)(params, x, y)\n",
    "    return [(w - lr * dw, b - lr * db) for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions collectively form the core components for constructing, training, and evaluating a neural network. The code emphasizes modularity, making it adaptable for various machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Minibatches with JAX for Efficient Training\n",
    "\n",
    "In this step, we implement a function to generate minibatches from given JAX tensors, a crucial practice for efficient training of machine learning models. Let's break down the code:\n",
    "\n",
    "### `get_minibatch` Function\n",
    "   - **Parameters:**\n",
    "      - `*tensors (jnp.ndarray)`: Variable number of JAX arrays representing input data.\n",
    "      - `minibatch_size (int)`: Size of each minibatch. Default is set to 1000.\n",
    "   - **Yields:**\n",
    "      - `Tuple[jnp.ndarray, ...]`: A tuple containing minibatches of input tensors.\n",
    "\n",
    "### Function Description\n",
    "   The `get_minibatch` function takes JAX tensors representing input data and generates minibatches of specified sizes. It uses JAX's random module to shuffle indices for each minibatch, ensuring randomness and avoiding bias during training. The function yields tuples of minibatches, making it suitable for efficient model training with large datasets.\n",
    "\n",
    "### Example Usage\n",
    "```python\n",
    "# Example usage with two input tensors X and y\n",
    "for minibatch_X, minibatch_y in get_minibatch(X, y, minibatch_size=128):\n",
    "    # Perform model training or evaluation on minibatch\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(*tensors: np.ndarray, \n",
    "                  minibatch_size: int = 1000) -> Iterable[Tuple[jnp.ndarray, ...]]:\n",
    "    \"\"\"\n",
    "    Generate minibatches from given JAX tensors.\n",
    "\n",
    "    Parameters:\n",
    "    - tensors (jnp.ndarray): Variable number of JAX arrays representing input data.\n",
    "    - minibatch_size (int): Size of each minibatch. Default is 1000.\n",
    "\n",
    "    Yields:\n",
    "    - Tuple[jnp.ndarray, ...]: A tuple containing minibatches of input tensors.\n",
    "    \"\"\"\n",
    "    n = tensors[0].shape[0]\n",
    "\n",
    "    # Check that all tensors have the same number of samples\n",
    "    for tensor in tensors:\n",
    "        assert tensor.shape[0] == n, \"All tensors must have the same number of samples.\"\n",
    "\n",
    "    # Randomly shuffle indices using JAX's random module\n",
    "     # Randomly shuffle indices\n",
    "    key = jax.random.PRNGKey(SEED)  # Use your desired PRNG key\n",
    "    idx = jax.random.permutation(key, jnp.arange(n), independent=True)\n",
    "\n",
    "\n",
    "    # Calculate the number of minibatches\n",
    "    n_minibatch = int(jnp.ceil(n / minibatch_size))\n",
    "\n",
    "    # Generate minibatches\n",
    "    for i in range(n_minibatch):\n",
    "        bidx = idx[i * minibatch_size: (i + 1) * minibatch_size]\n",
    "        yield tuple(jnp.array(t[bidx], dtype=jnp.float32)  for t in tensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code promotes efficient training by allowing the model to learn from subsets of the data in each iteration, facilitating convergence and scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training Parameters and Initializing Model\n",
    "\n",
    "Now that we have essential functions for training our neural network, let's set up the parameters and initialize the model.\n",
    "\n",
    "### Model Architecture\n",
    "We define the layer sizes of our neural network, representing the number of neurons in each layer. For example, a feedforward neural network with 784 input neurons, two hidden layers of 512 neurons each, and an output layer with 10 neurons:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [784, 512, 512, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Hyperparameters\n",
    "We set the number of training epochs, batch size, and the number of target classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "n_targets = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Model Parameters\n",
    "Now, we initialize the model parameters using the defined layer sizes and a random key for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = init_network_params(layer_sizes, random.PRNGKey(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters, along with the functions we've implemented, lay the foundation for training our neural network. Adjust these values based on your specific requirements or experimentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing the Training and Test Datasets\n",
    "\n",
    "In this section, we load and prepare the datasets for training and testing our neural network. We convert the raw data into JAX arrays and perform one-hot encoding for the target labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full train dataset (for checking accuracy while training)\n",
    "train_images = jnp.array(X_train)\n",
    "train_labels = one_hot(y_train, n_targets)\n",
    "\n",
    "test_images = jnp.array(X_test, dtype=jnp.float32)\n",
    "test_labels = one_hot(y_test, n_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neural Network\n",
    "\n",
    "In this section, we train our neural network using mini-batch stochastic gradient descent. The training loop runs for a specified number of epochs, and for each epoch, we update the model parameters based on mini-batches of the training data.\n",
    "\n",
    "```python\n",
    "Input: \n",
    "    learning_rate (γ)\n",
    "    max_epochs\n",
    "    model_params (θ)\n",
    "    objective_function (f(θ))\n",
    "    data_loader (providing minibatches)\n",
    "\n",
    "for epoch in 1 to max_epochs do\n",
    "    start_time = current_time()\n",
    "    \n",
    "    for minibatch_inputs, minibatch_outputs in data_loader do\n",
    "        # Compute gradients\n",
    "        gradients = ∇f(θ, minibatch_inputs, minibatch_outputs)\n",
    "\n",
    "        # Update model parameters\n",
    "        θ = θ - γ * gradients\n",
    "\n",
    "    epoch_time = current_time() - start_time\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f933ddc148e42b490f70cababb57f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 in 5.66 sec\n",
      "Training set accuracy: 0.9225\n",
      "Test set accuracy: 0.9246 \n",
      "\n",
      "Epoch 2 in 3.75 sec\n",
      "Training set accuracy: 0.9420\n",
      "Test set accuracy: 0.9416 \n",
      "\n",
      "Epoch 3 in 4.00 sec\n",
      "Training set accuracy: 0.9524\n",
      "Test set accuracy: 0.9504 \n",
      "\n",
      "Epoch 4 in 4.08 sec\n",
      "Training set accuracy: 0.9597\n",
      "Test set accuracy: 0.9567 \n",
      "\n",
      "Epoch 5 in 4.17 sec\n",
      "Training set accuracy: 0.9649\n",
      "Test set accuracy: 0.9600 \n",
      "\n",
      "Epoch 6 in 4.70 sec\n",
      "Training set accuracy: 0.9686\n",
      "Test set accuracy: 0.9639 \n",
      "\n",
      "Epoch 7 in 4.00 sec\n",
      "Training set accuracy: 0.9716\n",
      "Test set accuracy: 0.9665 \n",
      "\n",
      "Epoch 8 in 3.71 sec\n",
      "Training set accuracy: 0.9748\n",
      "Test set accuracy: 0.9688 \n",
      "\n",
      "Epoch 9 in 3.72 sec\n",
      "Training set accuracy: 0.9775\n",
      "Test set accuracy: 0.9697 \n",
      "\n",
      "Epoch 10 in 3.72 sec\n",
      "Training set accuracy: 0.9795\n",
      "Test set accuracy: 0.9709 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in trange(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate through minibatches of the training data\n",
    "    for inputs, outputs in get_minibatch(X_train, y_train, minibatch_size=batch_size):\n",
    "        outputs = one_hot(outputs, n_targets)\n",
    "        params = update(params, inputs, outputs, lr=0.01)\n",
    "    \n",
    "    # Calculate epoch time\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate training and test set accuracy\n",
    "    train_acc = accuracy(params, train_images, train_labels)\n",
    "    test_acc = accuracy(params, test_images, test_labels)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch+1, epoch_time))\n",
    "    print(\"Training set accuracy: {:0.4f}\".format(train_acc))\n",
    "    print(\"Test set accuracy: {:0.4f} \\n\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Visualization\n",
    "\n",
    "In this section, we select an example from the test dataset, make a prediction using the trained model parameters, and visualize the input image along with the prediction and ground truth label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Ground Truth\n",
    "We choose an index (`idx`) from the test dataset and extract the corresponding image and ground truth label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an index from the test dataset\n",
    "idx = 69\n",
    "\n",
    "# Extract image and ground truth label\n",
    "img = test_images[idx].reshape((28, 28))\n",
    "gt_lbl = test_labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Prediction\n",
    "Using the trained neural network, we make a prediction for the selected image and print both the predicted class and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the trained model parameters\n",
    "pred = jnp.argmax(predict(params, np.ravel(img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Visualization\n",
    "Finally, we visualize the input image using Matplotlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n",
      "Ground Truth: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the prediction and ground truth\n",
    "print('Prediction:', pred)\n",
    "print('Ground Truth:', gt_lbl)\n",
    "\n",
    "# Visualize the input image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This code snippet serves as a visual demonstration of the model's prediction capabilities and allows us to compare the predicted class with the actual ground truth label."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "poetry-kernel",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
